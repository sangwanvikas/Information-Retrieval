###############################################################################################################
# Get text for all AP89 corpus.
# Files generated by this script will be input for TopicModelProcessor to generate Doc-Topic matrix.
# Generate a file containing tuple (documentId, documentText) for all corpus documents.
###############################################################################################################
import os, sys, pickle, re
print os.curdir

currDirPath = os.path.abspath(os.curdir)
os.chdir("..")
srcDirPath =  os.path.abspath(os.curdir)

sys.path.append(srcDirPath +"/Resource")
sys.path.append(srcDirPath+"/ElasticSearchManager")

import Resource
from ElasticSearchManager import ElasticSearchManager

import Resource
############################################################################################################
class DataSetGenerator:
    def __init__(self, docIdCommaDocTextFilePath, indexName, docTypeName):
        # ---------------------------------------------------------------
        self._elasticSearchMgrObject = ElasticSearchManager(indexName, docTypeName, 0)
        # -------------------------------------------------------------
        # [
        #     ("AP85-101","Text from First document for AP-43"),
        #     ("AP85-102", "Text from second document for AP-43"),
        #     ("AP85-103","Text from First document for AP-43"),
        #     ("AP85-104", "Text from second document for AP-43")
        # ]
        self._docId_comma_documentsText_tuple_list = []
        self._docIdCommaDocTextFilePath = docIdCommaDocTextFilePath

    #######################################################################################################
    def __GetTextForAllDocuments__(self):
        allHits = self._elasticSearchMgrObject.__GetHitsForAllDocuments__()

        print "%d documents fetched from ElasticSearch !!\n" %(len(allHits))
        print "Cleaning data and dumping to a file ..."

        for hit in allHits:
            id = str(hit['_id'])
            text = str(hit['_source']['text'])
            textWithoutSmallWOrds =  re.sub(r'\b\w{1,4}\b', '', text)
            self._docId_comma_documentsText_tuple_list.append((id, textWithoutSmallWOrds))

        self.__DumpToPickleFile__( self._docId_comma_documentsText_tuple_list, self._docIdCommaDocTextFilePath)

    def __DumpToPickleFile__(self, data, filePath):
        with open (filePath, 'w') as handle:
            pickle.dump(data, handle)
        print "File saved. Location -> %s" %filePath

###########################################################################################################

obj = DataSetGenerator(Resource.DocIdCommaDocTextFilePath,
                             Resource.INDEX_NAME,
                             Resource.TYPE_NAME)
obj.__GetTextForAllDocuments__()